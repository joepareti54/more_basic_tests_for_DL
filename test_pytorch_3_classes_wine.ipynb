{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# joepareti54@gmail.com  May 6-13 2022\n",
    "#\n",
    "# classification of wine types \n",
    "# using a dataset built from wine.csv \n",
    "#\n",
    "# scaling and train-test split is implemented using sklearn\n",
    "# some issues on datatypes required by pytorch was resolved here:\n",
    "# https://stackoverflow.com/questions/60440292/runtimeerror-expected-scalar-type-long-but-found-float\n",
    "#\n",
    "# therefore the assignment in the training loop:\n",
    "# LAB = LAB.type(torch.LongTensor)\n",
    "#\n",
    "# moreover, the following data conversions are required on the transformed data:\n",
    "#\n",
    "#X_TRAIN = X_TRAIN.astype(dtype=np.float32)\n",
    "#y_train = y_train.astype(dtype=np.float32)\n",
    "#\n",
    "#The last layer of the nn is LogSoftmax\n",
    "#This returns logits that need to be converted into probabilities, and since they are log you need the exp function\n",
    "#\n",
    "#the last cell compares the top class of the prediction on test data vs. label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "#\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['1' '14.23' '1.71' '2.43' '15.6' '127' '2.8' '3.06' '0.28' '2.29'\n",
      "  '5.64' '1.04' '3.92' '1065']\n",
      " ['1' '13.2' '1.78' '2.14' '11.2' '100' '2.65' '2.76' '0.26' '1.28'\n",
      "  '4.38' '1.05' '3.4' '1050']]\n"
     ]
    }
   ],
   "source": [
    "#read the wine.csv file into a pandas dataframe\n",
    "data = np.asarray(pd.read_csv('./wine.csv', header = None))\n",
    "X = data[1:, :]\n",
    "print(X[0:2, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split in train and test array\n",
    "XX = X[:,1:]\n",
    "y = X[:,0]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X[:,1:], X[:,0], test_size=0.2, random_state=42)\n",
    "_train, X_test, y_train, y_test = train_test_split(XX, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaling\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_TRAIN = scaler.transform(X_train)\n",
    "X_TEST  = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to float32 numpy arrays\n",
    "X_TEST = X_TEST.astype(dtype=np.float32)\n",
    "y_test = y_test.astype(dtype=np.float32)\n",
    "X_TRAIN = X_TRAIN.astype(dtype=np.float32)\n",
    "y_train = y_train.astype(dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define tensor transformation\n",
    "transform =transforms.Compose([\n",
    "    transforms.ToTensor()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Wine(Dataset):\n",
    "    def __init__(self, file_flag,X_TRAIN, X_TEST, y_train,y_test, transform=transform):\n",
    "        if file_flag == 'TEST':\n",
    "            self.x = X_TEST \n",
    "            self.y = y_test\n",
    "            self.num_samples = X_TEST.shape[0]\n",
    "        else:\n",
    "            self.x = X_TRAIN\n",
    "            self.y = y_train\n",
    "            self.num_samples = X_TRAIN.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return(self.num_samples)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (self.x[index], self.y[index])\n",
    "#        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of train ds  142\n",
      "size of test  ds  36\n"
     ]
    }
   ],
   "source": [
    "#validate dataset class\n",
    "WineDS_TEST = Wine('TEST' ,X_TRAIN, X_TEST, y_train,y_test)\n",
    "WineDS_TRAIN= Wine('TRAIN',X_TRAIN, X_TEST, y_train,y_test)\n",
    "print('size of train ds ',len(WineDS_TRAIN))\n",
    "print('size of test  ds ',len(WineDS_TEST))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3415,  1.0321, -0.0030,  0.5887,  0.3806, -0.9270, -0.8016, -1.5493,\n",
      "         -1.3206, -0.0248, -0.7561, -1.8105, -0.4478],\n",
      "        [ 1.7142, -0.4417,  0.0688, -2.1708,  0.1066,  1.5908,  1.6369, -0.6105,\n",
      "          2.3246,  1.0515,  1.0443,  0.5659,  2.6957],\n",
      "        [-0.3782, -1.2225, -0.4343, -0.4279, -0.0989, -0.1402, -0.0621, -0.5322,\n",
      "         -0.2545, -1.0495,  1.1729,  0.7882, -0.9457],\n",
      "        [ 1.0535,  1.5321,  0.0688,  0.0078, -0.7839, -0.7696, -1.1714,  0.8760,\n",
      "         -0.0826,  1.7016, -1.6563, -1.3241, -0.8461]])\n",
      "----\n",
      "tensor([3., 1., 2., 3.])\n"
     ]
    }
   ],
   "source": [
    "#convert data to a dataloder suitable for mini-batch processing when training\n",
    "train_dataloader = DataLoader(WineDS_TRAIN, batch_size=4, shuffle=True)\n",
    "test_dataloader = DataLoader(WineDS_TEST, batch_size=4, shuffle=False)\n",
    "#\n",
    "train_features , train_labels = next(iter(train_dataloader))\n",
    "print(train_features)\n",
    "print('----')\n",
    "print(train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# \n",
    "class ThreeClassClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(13, 6)\n",
    "        self.fc2 = nn.Linear(6,4)\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = F.sigmoid(self.fc1(x))\n",
    "        x = F.log_softmax(self.fc2(x), dim=1)\n",
    "        return x\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ThreeClassClassification()\n",
    "loss = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "epochs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.03226637840271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/joepareti54/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:1639: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.674673497676849\n"
     ]
    }
   ],
   "source": [
    "for i in range(epochs):\n",
    "    running_loss = 0\n",
    "    for DATA, LAB in train_dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        LAB = LAB.type(torch.LongTensor)\n",
    "        log_ps = model(DATA)\n",
    "        LOSS = loss(log_ps, LAB)\n",
    "        \n",
    "        LOSS.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += LOSS.item()\n",
    "    else:\n",
    "        if i % 50 == 0:\n",
    "            print(running_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 1, 3, 1]]) tensor([1., 1., 3., 1.])\n",
      "tensor([[2, 1, 2, 3]]) tensor([2., 1., 2., 3.])\n",
      "tensor([[2, 3, 1, 3]]) tensor([2., 3., 1., 3.])\n",
      "tensor([[1, 2, 1, 2]]) tensor([1., 2., 1., 2.])\n",
      "tensor([[2, 2, 1, 2]]) tensor([2., 2., 1., 2.])\n",
      "tensor([[1, 2, 2, 3]]) tensor([1., 2., 2., 3.])\n",
      "tensor([[3, 3, 2, 2]]) tensor([3., 3., 2., 2.])\n",
      "tensor([[2, 1, 1, 2]]) tensor([2., 1., 1., 2.])\n",
      "tensor([[3, 1, 1, 1]]) tensor([3., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "#test the model\n",
    "for DATA, LAB in test_dataloader:\n",
    "    log_ps = model(DATA)\n",
    "#    print(torch.exp(log_ps), LAB)\n",
    "    ps = torch.exp(log_ps)\n",
    "    top_p, top_class = ps.topk(1, dim=1)\n",
    "    print(top_class.view(1,-1), LAB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#conclusion:\n",
    "# all predictions on the test set are right"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
